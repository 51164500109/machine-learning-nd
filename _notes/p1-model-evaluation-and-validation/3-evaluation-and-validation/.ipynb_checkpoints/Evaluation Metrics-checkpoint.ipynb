{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing\n",
    "\n",
    "Benefits of testing: \n",
    "- Gives estimate of performance on an independent dataset\n",
    "- Serves as a check on overfitting\n",
    "\n",
    "## Train/Test Split in sklearn\n",
    "\n",
    "Look for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.data.shape, iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test \\\n",
    "    = cross_validation.train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 4), (90,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 4), (60,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "\n",
    "### 1. Accuracy \n",
    "Accuracy = (no. of items in a class labelled correctly / all items in that class)\n",
    "\n",
    "Shortcomings:\n",
    "- Not ideal for skewed cases (very few Persons of Interest -> Denominator 'All items in that class' is small.)\n",
    "- May want to err on side of guessing innocent (or guilty, depending on consequences of labelling) -> i.e. asymmetries favouring different types of error.\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "[Confusion Matrix](images/14-01.png)\n",
    "\n",
    "Note: Tuning parameters can move the boundaries.\n",
    "\n",
    "[Decision Tree Confusion Matrix](images/14-02.png)\n",
    "\n",
    "[7x7 Confusion Matrix](images/14-03.png)\n",
    "\n",
    "### Recall: P(alg identifies as A | is A)\n",
    "(rows for true in rows, predicted in cols)\n",
    "- is like 'lacer' backwards which is similar to 'liar', and the opposite of a lie is the truth, so the denominator is the true values.\n",
    "- recall: finding X. i.e. P(finding X | ...)\n",
    "- Recall = TP/(TP + FN)\n",
    "\n",
    "### Precision: P(is A | alg identifies as A)\n",
    "- (columns for true in rows, prediction in cols)\n",
    "Starts with 'pre', so denominator is predicted.\n",
    "- Precision = TP/(TP + FP)\n",
    "\n",
    "### True positives, false positives, false negatives\n",
    "\n",
    "## F1 Score\n",
    "The harmonic mean of precision and recall.\n",
    "\n",
    "$$F_1 = 2 * \\frac{precision * recall}{precision + recall}$$\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Precision vs Recall\n",
    "\n",
    "# As with the previous exercises, let's look at the performance of a couple of classifiers\n",
    "# on the familiar Titanic dataset. Add a train/test split, then store the results in the\n",
    "# dictionary provided.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "\n",
    "X = X._get_numeric_data()\n",
    "y = X['Survived']\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "results = {\n",
    "  \"Naive Bayes Recall\": 0,\n",
    "  \"Naive Bayes Precision\": 0,\n",
    "  \"Decision Tree Recall\": 0,\n",
    "  \"Decision Tree Precision\": 0\n",
    "}\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print \"Decision Tree recall: {:.2f} and precision: {:.2f}\".format(recall(clf.predict(X_test),y_test),precision(clf.predict(X),y))\n",
    "\n",
    "results[\"Decision Tree Recall\"] = recall(clf.predict(X_test),y_test)\n",
    "results[\"Decision Tree Precision\"] = precision(clf.predict(X),y)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print \"GaussianNB recall: {:.2f} and precision: {:.2f}\".format(recall(clf.predict(X_test),y_test),precision(clf.predict(X),y))\n",
    "\n",
    "results[\"Naive Bayes Recall\"] = recall(clf.predict(X_test),y_test)\n",
    "results[\"Naive Bayes Precision\"] = precision(clf.predict(X),y)\n",
    "\n",
    "\"\"\"\n",
    "Decision Tree recall: 0.57 and precision: 0.92\n",
    "GaussianNB recall: 0.70 and precision: 0.40\n",
    "The answer you've submitted is: {'Decision Tree Recall': 0.56944444444444442, 'Naive Bayes Recall': 0.69565217391304346, 'Decision Tree Precision': 0.91812865497076024, 'Naive Bayes Precision': 0.40058479532163743}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
