{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning: Artificial Intelligence x Data Science\n",
    "\n",
    "AI -> Cognitive Systems (thinking like humans) vs Machine Learning\n",
    "\n",
    "#### Conundrums in AI:\n",
    "1. Intelligent agents have limited resources (computational speed, memory) -> But many problems are computationally intractable.\n",
    "2. Computation is local, but problems have global constraints.\n",
    "3. Logic is deductive, but many problems are not (they are abductive or inductive).\n",
    "4. The world is dynamic, but knowledge is limited. AI agent always begins with what it knows -> How does it address new problems?\n",
    "5. Problem solving, reasoning and learning are complex, but explanation and justification are even more complex.\n",
    "\n",
    "#### Characteristics of AI Problems:\n",
    "1. Knowledge often arrives incrementally.\n",
    "2. Problems exhibit recurring patterns.\n",
    "3. Problems have multiple levels of granularity.\n",
    "4. Many problems are computationally intractable.\n",
    "5. The world is dynamic, but knowledge of the world is static.\n",
    "6. The world is open-ended, but knowledge is limited.\n",
    "\n",
    "(From [Knowledge-Based AI](https://www.udacity.com/course/knowledge-based-ai-cognitive-systems--ud409?_ga=1.192741295.463903328.1463823313))\n",
    "\n",
    "#### AI As Uncertainty Management\n",
    "AI = what to do when you don't know what to do\n",
    "\n",
    "Reasons for uncertainty:\n",
    "- Sensor limits\n",
    "- Adversaries\n",
    "- Stochastic environments (rolling dice)\n",
    "- Laziness (Can compute what situation is but too lazy to do it)\n",
    "- Ignorance (Could know something but just don't care)\n",
    "\n",
    "(From uDacity Sebastian Thrun)\n",
    "\n",
    "e.g.: Watson (answering Jeopardy questions)\n",
    "\n",
    "Process:\n",
    "- Read clue (understand natural language sentences)\n",
    "- Search through knowledge base\n",
    "- Decide on answer\n",
    "- Phrase answer\n",
    "\n",
    "Specifics:\n",
    "- Know of the potential answers (e.g. Michael Phelps, Hey Jude) and know information pertaining to the potential answers\n",
    "- Understand the statement: Interpret words in context. May need to interpret puns.\n",
    "- Know the format of the answer\n",
    "\n",
    "Core **deliberation processes**:\n",
    "1. Reasoning (read and generate natural language sentences)\n",
    "2. Learning (make decisions and see if those decisions are correct or not -> Change)\n",
    "3. Memory (Store knowledge and what we learn)\n",
    "\n",
    "[img](images/intro-1.png)\n",
    "\n",
    "#### Four schools of thought of AI\n",
    "[Four quadrants (schools of thought) of AI](images/intro-2.png)\n",
    "\n",
    "Thinking vs acting,\n",
    "Optimally vs like humans.\n",
    "\n",
    "Knowledge-based AI: interested in agents that think like humans.\n",
    "Examples:\n",
    "[Examples of applications in each school of thought of AI](images/intro-3.png)\n",
    "\n",
    "E.g. autonomous vehicle: acts (and thinks?) optimally.\n",
    "\n",
    "Patterns of knowledge-based data: AI behaviour \n",
    "\n",
    "[Categorising four examples](images/intro-4.png)\n",
    "\n",
    "### Bayes' Rule\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)*P(A)}{P(B)}$$\n",
    "\n",
    "$$ Posterior = \\frac{Likelihood x Prior}{Marginal likelihood}$$\n",
    "\n",
    "Likelihood: If we knew the cause (A), what would be the probability of the evidence we just observed? But to correct for the inversion, we need to multiply by the prior.\n",
    "\n",
    "$$P(B) = \\sum_aP(B|A=a)P(A=a)$$\n",
    "\n",
    "(Total probability)\n",
    "\n",
    "#### Bayes Network\n",
    "[Bayes Network](images/intro-5.png)\n",
    "\n",
    "Number of parameters in this Bayes Network: 3. P(A), P(B|A), P(B| not A).\n",
    "\n",
    "Data is a lot about discerning unseen cause of the data that we can see.\n",
    "\n",
    "## Data Science\n",
    "\n",
    "[What is a data scientist?](images/intro-ds1.png)\n",
    "\n",
    "'Substantive Expertise':\n",
    "- Know which questions to ask\n",
    "- Can interpret the data well\n",
    "- Understands structure of the data\n",
    "\n",
    "But data scientists often work in teams so they can complement each other's strengths and weaknesses.\n",
    "\n",
    "[Data Science Process](images/intro-ds2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "What is ML?\n",
    "\n",
    "Philosophy of ML:\n",
    "- Theoretical (Michael) vs Practical (Charles)\n",
    "\n",
    "\n",
    "Theoretical: ML is computational statistics that is about proving theorems.\n",
    "Practical: ML is the broader notion of building computational artifacts that learn over time based on experience. Applied stats.\n",
    "\n",
    "(They are hilarious.)\n",
    "\n",
    "Supervised learning:\n",
    "- Taking labelled datasets, gleaning info from it so you can label new datasets.\n",
    "- Function approximation\n",
    "- Approximate function induction\n",
    "-> Make assumptions about the world, e.g. well-behaved function that fits that data that is generalises.\n",
    "\n",
    "Supervised learning is about **inductive bias**. Specifics -> Generalities.\n",
    "\n",
    "Vs deduction: Generalities -> Specifics.\n",
    "\n",
    "### Induction, deduction and abduction\n",
    "\n",
    "[ida](images/intro-ida.png)\n",
    "\n",
    "Deduction: Given the rule and the cause, deduce the effect. (Proof-preserving)\n",
    "\n",
    "[d](images/intro-d.png)\n",
    "\n",
    "Induction: Given a cause and an effect, induce a rule. (Correctness not guaranteed.)\n",
    "\n",
    "[i](images/intro-i.png)\n",
    "\n",
    "Abduction: Given a rule and an effect, abduce a cause. (Correctness not guaranteed.)\n",
    "\n",
    "[a](images/intro-a.png)\n",
    "\n",
    "ML is about **inducing a rule**. The rule doesn't have to be causal - correlations are useful too.\n",
    "\n",
    "E.g. apply abductively to figure out where insider trading has occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "**Description or summarisation** (vs supervised learning -> Approximation).\n",
    "Just have input, no given labels. Derive structure from input.\n",
    "\n",
    "Differences with supervised learning:\n",
    "- All ways of dividing up the world are in a way equally good (absent other signals telling you something is goood or not good).\n",
    "- Unsupervised is helpful in supervised -> Can help\n",
    "\n",
    "[unsup](images/intro-unsup.png)\n",
    "\n",
    "## Reinforcement Learning\n",
    "\n",
    "Learning from delayed reward vs supervised learning 'here's what you should do'.\n",
    "\n",
    "E.g. Playing tic-tac-toe -> lost -> learn which moves were important (bad).\n",
    "\n",
    "Reinforcement learn is in a sense harder than supervised learning because you're not told what to do.\n",
    "Like playing a game without knowing any of the rules but being told once in a while that you've won or you've lost.\n",
    "\n",
    "## Comparison of three parts of ML\n",
    "\n",
    "Supervised: Labels. \n",
    "Unsupervised: Don't know if one cluster is better than another.\n",
    "-> But there is an assumed set of labels because you're clustering.\n",
    "\n",
    "- In many cases you can formulate these problems as some sort of optimisation.\n",
    "    - SL: Labels data well\n",
    "    - RL: Behaviour scores well\n",
    "    - UL: Cluster scores well\n",
    "\n",
    "One view:\n",
    "Compsci hink in terms of algorithms, theorems vs ML data being central. Or the two being co-equal.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
